{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bqrg0Bh6wMMx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "class TinyImageNetTF:\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Initialize TinyImageNet dataset\n",
    "        Args:\n",
    "            root_dir (str): Directory to store/load the dataset\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.image_size = 64\n",
    "        self.num_classes = 200\n",
    "\n",
    "        # Download dataset if it doesn't exist\n",
    "        if not os.path.exists(os.path.join(root_dir, 'tiny-imagenet-200')):\n",
    "            self._download_dataset()\n",
    "\n",
    "        # Create class mapping\n",
    "        train_dir = os.path.join(root_dir, 'tiny-imagenet-200', 'train')\n",
    "        self.class_names = sorted(os.listdir(train_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "    def _download_dataset(self):\n",
    "        \"\"\"Download and extract the Tiny ImageNet dataset\"\"\"\n",
    "        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        print(f\"Downloading Tiny ImageNet from {url}...\")\n",
    "\n",
    "        # Create directory\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "\n",
    "        # Download the file\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "        # Save the zip file\n",
    "        zip_path = os.path.join(self.root_dir, \"tiny-imagenet-200.zip\")\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            for data in tqdm(response.iter_content(chunk_size=1024),\n",
    "                           total=total_size//1024, unit='KB'):\n",
    "                f.write(data)\n",
    "\n",
    "        # Extract the archive\n",
    "        print(\"Extracting files...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.root_dir)\n",
    "\n",
    "        # Clean up\n",
    "        os.remove(zip_path)\n",
    "        print(\"Download and extraction complete!\")\n",
    "\n",
    "    def _parse_image(self, filename, label):\n",
    "        \"\"\"Parse image and convert to float32.\"\"\"\n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "\n",
    "    def _augment(self, image, label):\n",
    "        \"\"\"Apply data augmentation to training images.\"\"\"\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image, 0.2)\n",
    "        return image, label\n",
    "\n",
    "    def get_dataset(self, split='train', batch_size=128, shuffle=True, augment=True):\n",
    "        \"\"\"\n",
    "        Get TensorFlow dataset for specified split\n",
    "        Args:\n",
    "            split (str): 'train', 'val', or 'test'\n",
    "            batch_size (int): Batch size\n",
    "            shuffle (bool): Whether to shuffle the dataset\n",
    "            augment (bool): Whether to apply data augmentation (only for training)\n",
    "        Returns:\n",
    "            tf.data.Dataset\n",
    "        \"\"\"\n",
    "        base_path = os.path.join(self.root_dir, 'tiny-imagenet-200')\n",
    "\n",
    "        if split == 'train':\n",
    "            # Process training data\n",
    "            filenames = []\n",
    "            labels = []\n",
    "            for class_name in self.class_names:\n",
    "                class_dir = os.path.join(base_path, 'train', class_name, 'images')\n",
    "                class_files = [os.path.join(class_dir, f) for f in os.listdir(class_dir)]\n",
    "                filenames.extend(class_files)\n",
    "                labels.extend([self.class_to_idx[class_name]] * len(class_files))\n",
    "\n",
    "        elif split == 'val':\n",
    "            # Process validation data\n",
    "            val_annotations = pd.read_csv(\n",
    "                os.path.join(base_path, 'val', 'val_annotations.txt'),\n",
    "                sep='\\t', header=None,\n",
    "                names=['filename', 'class', 'x', 'y', 'w', 'h']\n",
    "            )\n",
    "            filenames = [os.path.join(base_path, 'val', 'images', f)\n",
    "                        for f in val_annotations['filename']]\n",
    "            labels = [self.class_to_idx[c] for c in val_annotations['class']]\n",
    "\n",
    "        else:  # test\n",
    "            # For test data, we only have images without labels\n",
    "            test_dir = os.path.join(base_path, 'test', 'images')\n",
    "            filenames = [os.path.join(test_dir, f) for f in os.listdir(test_dir)]\n",
    "            labels = [0] * len(filenames)  # Dummy labels for test set\n",
    "\n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "        # Parse images\n",
    "        dataset = dataset.map(self._parse_image,\n",
    "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        # Apply augmentation if needed\n",
    "        if split == 'train' and augment:\n",
    "            dataset = dataset.map(self._augment,\n",
    "                                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        # Shuffle if needed\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "        # Batch and prefetch\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "def get_tiny_imagenet_datasets(root_dir, batch_size=128):\n",
    "    \"\"\"\n",
    "    Get train, validation, and test datasets\n",
    "    \"\"\"\n",
    "    dataset = TinyImageNetTF(root_dir)\n",
    "\n",
    "    train_ds = dataset.get_dataset('train', batch_size=batch_size,\n",
    "                                 shuffle=True, augment=True)\n",
    "    val_ds = dataset.get_dataset('val', batch_size=batch_size,\n",
    "                               shuffle=False, augment=False)\n",
    "    test_ds = dataset.get_dataset('test', batch_size=batch_size,\n",
    "                                shuffle=False, augment=False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0D8fkF1wVqq",
    "outputId": "d337c5f8-95ab-4f48-fa80-16edec89f2ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch information:\n",
      "Image batch shape: (128, 64, 64, 3)\n",
      "Label batch shape: (128,)\n",
      "Image value range: (-0.20, 1.20)\n",
      "\n",
      "Counting samples (this might take a moment)...\n",
      "Training samples: 100000\n",
      "Validation samples: 10000\n",
      "Test samples: 10000\n",
      "\n",
      "Quick dataset size check:\n",
      "Batch size: 128\n",
      "\n",
      "Checking directory structure:\n",
      "Train directory exists: True\n",
      "Val directory exists: True\n",
      "Test directory exists: True\n",
      "Number of training classes: 200\n",
      "Error displaying images: No module named 'matplotlib'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the directory\n",
    "root_dir = \"./tiny-imagenet-200\"\n",
    "\n",
    "# Get the datasets\n",
    "train_ds, val_ds, test_ds = get_tiny_imagenet_datasets(root_dir)\n",
    "\n",
    "# 1. Check the first batch\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"\\nFirst batch information:\")\n",
    "    print(f\"Image batch shape: {images.shape}\")  # Should be (batch_size, 64, 64, 3)\n",
    "    print(f\"Label batch shape: {labels.shape}\")  # Should be (batch_size,)\n",
    "    print(f\"Image value range: ({tf.reduce_min(images).numpy():.2f}, {tf.reduce_max(images).numpy():.2f})\")\n",
    "\n",
    "# 2. Count total samples (corrected version)\n",
    "def count_samples(dataset):\n",
    "    count = 0\n",
    "    for images, labels in dataset:\n",
    "        count += images.shape[0]  # Add batch size\n",
    "    return count\n",
    "\n",
    "print(\"\\nCounting samples (this might take a moment)...\")\n",
    "try:\n",
    "    train_count = count_samples(train_ds)\n",
    "    val_count = count_samples(val_ds)\n",
    "    test_count = count_samples(test_ds)\n",
    "\n",
    "    print(f\"Training samples: {train_count}\")     # Should be ~100,000\n",
    "    print(f\"Validation samples: {val_count}\")     # Should be ~10,000\n",
    "    print(f\"Test samples: {test_count}\")         # Should be ~10,000\n",
    "except Exception as e:\n",
    "    print(f\"Error counting samples: {e}\")\n",
    "\n",
    "# Quick alternative count (faster but might be less accurate)\n",
    "print(\"\\nQuick dataset size check:\")\n",
    "for images, labels in train_ds.take(1):\n",
    "    batch_size = images.shape[0]\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# 3. Check directory structure and files\n",
    "import os\n",
    "\n",
    "base_path = os.path.join(root_dir, 'tiny-imagenet-200')\n",
    "print(\"\\nChecking directory structure:\")\n",
    "print(f\"Train directory exists: {os.path.exists(os.path.join(base_path, 'train'))}\")\n",
    "print(f\"Val directory exists: {os.path.exists(os.path.join(base_path, 'val'))}\")\n",
    "print(f\"Test directory exists: {os.path.exists(os.path.join(base_path, 'test'))}\")\n",
    "\n",
    "# Check number of class directories in train\n",
    "if os.path.exists(os.path.join(base_path, 'train')):\n",
    "    train_classes = len(os.listdir(os.path.join(base_path, 'train')))\n",
    "    print(f\"Number of training classes: {train_classes}\")  # Should be 200\n",
    "\n",
    "# 4. Display a few images\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for images, labels in train_ds.take(1):\n",
    "        for j in range(min(5, images.shape[0])):  # Show first 5 images or less\n",
    "            plt.subplot(1, 5, j+1)\n",
    "            plt.imshow(images[j].numpy())\n",
    "            plt.title(f'Label: {labels[j].numpy()}')\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying images: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ibriu_s4EkBQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 13:58:44,378 - __main__ - INFO - \n",
      "Processing dataset: cifar10\n",
      "2024-11-29 13:58:44,379 - __main__ - INFO - Loading cifar10 dataset...\n",
      "2024-11-29 13:58:44,808 - __main__ - INFO - CIFAR-10 loaded: train shapes (50000, 32, 32, 3), (50000, 1)\n",
      "2024-11-29 13:58:45,305 - __main__ - INFO - Created data generators successfully:\n",
      "2024-11-29 13:58:45,306 - __main__ - INFO - Training samples: 40000\n",
      "2024-11-29 13:58:45,307 - __main__ - INFO - Validation samples: 10000\n",
      "2024-11-29 13:58:45,307 - __main__ - INFO - Test samples: 10000\n",
      "2024-11-29 13:58:45,473 - __main__ - INFO - Starting training for cifar10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "625/625 [==============================] - 21s 25ms/step - loss: 1.7014 - accuracy: 0.0968 - val_loss: 1.4839 - val_accuracy: 0.0591 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 1.2690 - accuracy: 0.1016 - val_loss: 1.2322 - val_accuracy: 0.0431 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 1.0827 - accuracy: 0.1009 - val_loss: 1.0165 - val_accuracy: 0.0770 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 15s 23ms/step - loss: 0.9756 - accuracy: 0.1016 - val_loss: 0.8424 - val_accuracy: 0.0935 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 15s 23ms/step - loss: 0.9024 - accuracy: 0.1029 - val_loss: 1.2289 - val_accuracy: 0.1366 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8440 - accuracy: 0.1026 - val_loss: 0.9076 - val_accuracy: 0.0924 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.1029\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7971 - accuracy: 0.1029 - val_loss: 0.9253 - val_accuracy: 0.0516 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7199 - accuracy: 0.1037 - val_loss: 0.6589 - val_accuracy: 0.0972 - lr: 5.0000e-04\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6970 - accuracy: 0.1029 - val_loss: 0.7254 - val_accuracy: 0.0833 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.6741 - accuracy: 0.1038 - val_loss: 0.7511 - val_accuracy: 0.0808 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.6552 - accuracy: 0.1033 - val_loss: 0.6213 - val_accuracy: 0.1030 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.6373 - accuracy: 0.1044 - val_loss: 0.6615 - val_accuracy: 0.1008 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6270 - accuracy: 0.1030 - val_loss: 0.5801 - val_accuracy: 0.0841 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.6100 - accuracy: 0.1035 - val_loss: 0.5763 - val_accuracy: 0.0882 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.6064 - accuracy: 0.1033 - val_loss: 0.5834 - val_accuracy: 0.0981 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:02:45,953 - __main__ - INFO - Applying Gradient-based to cifar10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:03:37,270 - __main__ - INFO - Completed Gradient-based for cifar10\n",
      "2024-11-29 14:03:37,270 - __main__ - WARNING - Gradient-based did not meet expected performance targets\n",
      "2024-11-29 14:03:37,286 - __main__ - INFO - Applying Influence Functions to cifar10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step\n",
      "282/282 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:04:56,285 - __main__ - INFO - Completed Influence Functions for cifar10\n",
      "2024-11-29 14:04:56,285 - __main__ - WARNING - Influence Functions did not meet expected performance targets\n",
      "2024-11-29 14:04:56,304 - __main__ - INFO - Applying Hessian-Guided to cifar10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:06:08,416 - __main__ - INFO - Completed Hessian-Guided for cifar10\n",
      "2024-11-29 14:06:08,417 - __main__ - WARNING - Hessian-Guided did not meet expected performance targets\n",
      "2024-11-29 14:06:08,434 - __main__ - INFO - Applying Combined Method to cifar10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "282/282 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:07:07,702 - __main__ - INFO - Completed Combined Method for cifar10\n",
      "2024-11-29 14:07:07,702 - __main__ - WARNING - Combined Method did not meet expected performance targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      " 1/32 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:462: RuntimeWarning: overflow encountered in exp\n",
      "  mask = 1.0 / (1.0 + np.exp((weight_abs - threshold) / (threshold * 0.1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:07:10,032 - __main__ - INFO - \n",
      "Processing dataset: cifar100\n",
      "2024-11-29 14:07:10,033 - __main__ - INFO - Loading cifar100 dataset...\n",
      "2024-11-29 14:07:10,380 - __main__ - INFO - CIFAR-100 loaded: train shapes (50000, 32, 32, 3), (50000, 1)\n",
      "2024-11-29 14:07:10,906 - __main__ - INFO - Created data generators successfully:\n",
      "2024-11-29 14:07:10,907 - __main__ - INFO - Training samples: 40000\n",
      "2024-11-29 14:07:10,908 - __main__ - INFO - Validation samples: 10000\n",
      "2024-11-29 14:07:10,908 - __main__ - INFO - Test samples: 10000\n",
      "2024-11-29 14:07:11,194 - __main__ - INFO - Starting training for cifar100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/313 [..............................] - ETA: 39s - loss: 5.8442 - accuracy: 0.0078  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0540s vs `on_train_batch_end` time: 0.0617s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:07:15,244 - tensorflow - WARNING - Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0540s vs `on_train_batch_end` time: 0.0617s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 48s 142ms/step - loss: 4.3064 - accuracy: 0.0095 - val_loss: 3.8573 - val_accuracy: 0.0062 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 3.6746 - accuracy: 0.0131 - val_loss: 3.5530 - val_accuracy: 0.0159 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 3.2906 - accuracy: 0.0118 - val_loss: 3.1027 - val_accuracy: 0.0050 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 2.9728 - accuracy: 0.0117 - val_loss: 2.8640 - val_accuracy: 0.0158 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 2.6945 - accuracy: 0.0110 - val_loss: 2.6960 - val_accuracy: 0.0080 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 2.4713 - accuracy: 0.0104 - val_loss: 2.3889 - val_accuracy: 0.0095 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.2996 - accuracy: 0.0106 - val_loss: 2.3472 - val_accuracy: 0.0059 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.1508 - accuracy: 0.0102 - val_loss: 2.2419 - val_accuracy: 0.0055 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.0291 - accuracy: 0.0097 - val_loss: 2.0803 - val_accuracy: 0.0065 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.9215 - accuracy: 0.0102 - val_loss: 2.0337 - val_accuracy: 0.0090 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.8174 - accuracy: 0.0100 - val_loss: 2.0692 - val_accuracy: 0.0074 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.7124 - accuracy: 0.0095 - val_loss: 2.0877 - val_accuracy: 0.0114 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.6472 - accuracy: 0.0099 - val_loss: 1.8489 - val_accuracy: 0.0087 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.5739 - accuracy: 0.0100 - val_loss: 1.9255 - val_accuracy: 0.0076 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.4980 - accuracy: 0.0100 - val_loss: 1.8134 - val_accuracy: 0.0100 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.4429 - accuracy: 0.0100 - val_loss: 1.9874 - val_accuracy: 0.0122 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.3739 - accuracy: 0.0100 - val_loss: 2.0191 - val_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.3264 - accuracy: 0.0099 - val_loss: 1.5013 - val_accuracy: 0.0110 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.2760 - accuracy: 0.0100 - val_loss: 2.0433 - val_accuracy: 0.0050 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.2195 - accuracy: 0.0098 - val_loss: 1.5311 - val_accuracy: 0.0108 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:22:29,917 - __main__ - INFO - Applying Gradient-based to cifar100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step\n",
      "310/310 [==============================] - 3s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:22:48,853 - __main__ - INFO - Completed Gradient-based for cifar100\n",
      "2024-11-29 14:22:48,854 - __main__ - WARNING - Gradient-based did not meet expected performance targets\n",
      "2024-11-29 14:22:48,911 - __main__ - INFO - Applying Influence Functions to cifar100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "310/310 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:25:00,917 - __main__ - INFO - Completed Influence Functions for cifar100\n",
      "2024-11-29 14:25:00,917 - __main__ - WARNING - Influence Functions did not meet expected performance targets\n",
      "2024-11-29 14:25:00,981 - __main__ - INFO - Applying Hessian-Guided to cifar100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "310/310 [==============================] - 3s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:27:08,272 - __main__ - INFO - Completed Hessian-Guided for cifar100\n",
      "2024-11-29 14:27:08,273 - __main__ - WARNING - Hessian-Guided did not meet expected performance targets\n",
      "2024-11-29 14:27:08,339 - __main__ - INFO - Applying Combined Method to cifar100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "310/310 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:28:53,572 - __main__ - INFO - Completed Combined Method for cifar100\n",
      "2024-11-29 14:28:53,573 - __main__ - WARNING - Combined Method did not meet expected performance targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "310/310 [==============================] - 3s 11ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "310/310 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:29:03,238 - __main__ - INFO - \n",
      "Processing dataset: fashion_mnist\n",
      "2024-11-29 14:29:03,238 - __main__ - INFO - Loading fashion_mnist dataset...\n",
      "2024-11-29 14:29:03,550 - __main__ - INFO - Fashion-MNIST loaded: train shapes (60000, 28, 28, 1), (60000,)\n",
      "2024-11-29 14:29:03,753 - __main__ - INFO - Created data generators successfully:\n",
      "2024-11-29 14:29:03,754 - __main__ - INFO - Training samples: 48000\n",
      "2024-11-29 14:29:03,754 - __main__ - INFO - Validation samples: 12000\n",
      "2024-11-29 14:29:03,755 - __main__ - INFO - Test samples: 10000\n",
      "2024-11-29 14:29:03,889 - __main__ - INFO - Starting training for fashion_mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.7818 - accuracy: 0.7146 - val_loss: 0.5329 - val_accuracy: 0.7909 - lr: 0.0010\n",
      "Epoch 2/12\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.5109 - accuracy: 0.8082 - val_loss: 0.4016 - val_accuracy: 0.8474 - lr: 0.0010\n",
      "Epoch 3/12\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.4384 - accuracy: 0.8371 - val_loss: 0.3448 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 4/12\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:29:49,169 - __main__ - INFO - Reached target retention accuracy at epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 13s 17ms/step - loss: 0.4053 - accuracy: 0.8497 - val_loss: 0.3030 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 5/12\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.8616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:29:59,323 - __main__ - INFO - Reached target retention accuracy at epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3757 - accuracy: 0.8615 - val_loss: 0.3093 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 6/12\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:30:10,012 - __main__ - INFO - Reached target retention accuracy at epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 11s 14ms/step - loss: 0.3580 - accuracy: 0.8671 - val_loss: 0.3023 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 7/12\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.8759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:30:20,289 - __main__ - INFO - Reached target retention accuracy at epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3412 - accuracy: 0.8758 - val_loss: 0.2813 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 8/12\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:30:32,754 - __main__ - INFO - Reached target retention accuracy at epoch 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 12s 17ms/step - loss: 0.3282 - accuracy: 0.8794 - val_loss: 0.2599 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 9/12\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.8832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:30:43,430 - __main__ - INFO - Reached target retention accuracy at epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 11s 14ms/step - loss: 0.3172 - accuracy: 0.8832 - val_loss: 0.2719 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 10/12\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:30:55,177 - __main__ - INFO - Reached target retention accuracy at epoch 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3089 - accuracy: 0.8873 - val_loss: 0.2473 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 11/12\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.8862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:05,510 - __main__ - INFO - Reached target retention accuracy at epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3065 - accuracy: 0.8862 - val_loss: 0.2567 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 12/12\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:17,895 - __main__ - INFO - Reached target retention accuracy at epoch 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2949 - accuracy: 0.8918 - val_loss: 0.2343 - val_accuracy: 0.9146 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:18,012 - __main__ - INFO - Applying Gradient-based to fashion_mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:32:18,719 - __main__ - INFO - Completed Gradient-based for fashion_mnist\n",
      "2024-11-29 14:32:18,720 - __main__ - WARNING - Gradient-based did not meet expected performance targets\n",
      "2024-11-29 14:32:18,733 - __main__ - INFO - Applying Influence Functions to fashion_mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:33:50,325 - __main__ - INFO - Completed Influence Functions for fashion_mnist\n",
      "2024-11-29 14:33:50,325 - __main__ - WARNING - Influence Functions did not meet expected performance targets\n",
      "2024-11-29 14:33:50,337 - __main__ - INFO - Applying Hessian-Guided to fashion_mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:35:14,350 - __main__ - INFO - Completed Hessian-Guided for fashion_mnist\n",
      "2024-11-29 14:35:14,351 - __main__ - WARNING - Hessian-Guided did not meet expected performance targets\n",
      "2024-11-29 14:35:14,376 - __main__ - INFO - Applying Combined Method to fashion_mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:36:17,419 - __main__ - INFO - Completed Combined Method for fashion_mnist\n",
      "2024-11-29 14:36:17,420 - __main__ - WARNING - Combined Method did not meet expected performance targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:36:19,275 - __main__ - INFO - \n",
      "Processing dataset: svhn\n",
      "2024-11-29 14:36:19,276 - __main__ - INFO - Loading svhn dataset...\n",
      "2024-11-29 14:36:19,279 - absl - INFO - Load dataset info from C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0\n",
      "2024-11-29 14:36:19,294 - absl - INFO - Reusing dataset svhn_cropped (C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0)\n",
      "2024-11-29 14:36:19,295 - absl - INFO - Constructing tf.data.Dataset svhn_cropped for split train, from C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0\n",
      "2024-11-29 14:36:19,327 - absl - INFO - Load dataset info from C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0\n",
      "2024-11-29 14:36:19,329 - absl - INFO - Reusing dataset svhn_cropped (C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0)\n",
      "2024-11-29 14:36:19,329 - absl - INFO - Constructing tf.data.Dataset svhn_cropped for split test, from C:\\Users\\khoda\\tensorflow_datasets\\svhn_cropped\\3.0.0\n",
      "2024-11-29 14:36:29,408 - __main__ - INFO - SVHN loaded: train shapes (73257, 32, 32, 3), (73257, 1)\n",
      "2024-11-29 14:36:30,447 - __main__ - INFO - Created data generators successfully:\n",
      "2024-11-29 14:36:30,447 - __main__ - INFO - Training samples: 58605\n",
      "2024-11-29 14:36:30,448 - __main__ - INFO - Validation samples: 14652\n",
      "2024-11-29 14:36:30,448 - __main__ - INFO - Test samples: 26032\n",
      "2024-11-29 14:36:30,573 - __main__ - INFO - Starting training for svhn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "458/458 [==============================] - 22s 45ms/step - loss: 1.9012 - accuracy: 0.0450 - val_loss: 1.0969 - val_accuracy: 0.0383 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "458/458 [==============================] - 20s 45ms/step - loss: 0.9325 - accuracy: 0.0660 - val_loss: 0.4789 - val_accuracy: 0.0582 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.6836 - accuracy: 0.0672 - val_loss: 0.4104 - val_accuracy: 0.0590 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.5841 - accuracy: 0.0665 - val_loss: 0.3939 - val_accuracy: 0.0614 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "458/458 [==============================] - 21s 45ms/step - loss: 0.5217 - accuracy: 0.0671 - val_loss: 0.3261 - val_accuracy: 0.0639 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.4835 - accuracy: 0.0670 - val_loss: 0.3145 - val_accuracy: 0.0661 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.4479 - accuracy: 0.0677 - val_loss: 0.3087 - val_accuracy: 0.0642 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "458/458 [==============================] - 22s 48ms/step - loss: 0.4293 - accuracy: 0.0669 - val_loss: 0.3103 - val_accuracy: 0.0590 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "458/458 [==============================] - 22s 47ms/step - loss: 0.4114 - accuracy: 0.0679 - val_loss: 0.2807 - val_accuracy: 0.0646 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "458/458 [==============================] - 21s 45ms/step - loss: 0.4004 - accuracy: 0.0671 - val_loss: 0.2599 - val_accuracy: 0.0656 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "458/458 [==============================] - 22s 47ms/step - loss: 0.3838 - accuracy: 0.0673 - val_loss: 0.2882 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.3688 - accuracy: 0.0675 - val_loss: 0.2677 - val_accuracy: 0.0659 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.3608 - accuracy: 0.0676 - val_loss: 0.2479 - val_accuracy: 0.0643 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "458/458 [==============================] - 21s 45ms/step - loss: 0.3508 - accuracy: 0.0675 - val_loss: 0.2617 - val_accuracy: 0.0701 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "458/458 [==============================] - 21s 46ms/step - loss: 0.3403 - accuracy: 0.0677 - val_loss: 0.2575 - val_accuracy: 0.0680 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:41:47,405 - __main__ - INFO - Applying Gradient-based to svhn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:42:37,541 - __main__ - INFO - Completed Gradient-based for svhn\n",
      "2024-11-29 14:42:37,541 - __main__ - WARNING - Gradient-based did not meet expected performance targets\n",
      "2024-11-29 14:42:37,559 - __main__ - INFO - Applying Influence Functions to svhn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:44:13,858 - __main__ - INFO - Completed Influence Functions for svhn\n",
      "2024-11-29 14:44:13,858 - __main__ - WARNING - Influence Functions did not meet expected performance targets\n",
      "2024-11-29 14:44:13,875 - __main__ - INFO - Applying Hessian-Guided to svhn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 4ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:45:44,149 - __main__ - INFO - Completed Hessian-Guided for svhn\n",
      "2024-11-29 14:45:44,149 - __main__ - WARNING - Hessian-Guided did not meet expected performance targets\n",
      "2024-11-29 14:45:44,166 - __main__ - INFO - Applying Combined Method to svhn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:46:54,052 - __main__ - INFO - Completed Combined Method for svhn\n",
      "2024-11-29 14:46:54,053 - __main__ - WARNING - Combined Method did not meet expected performance targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "759/759 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:46:58,904 - __main__ - INFO - \n",
      "Processing dataset: tiny_imagenet\n",
      "2024-11-29 14:46:58,905 - __main__ - INFO - Loading tiny_imagenet dataset...\n",
      "2024-11-29 14:46:58,905 - __main__ - INFO - Getting TinyImageNet datasets...\n",
      "2024-11-29 14:47:00,563 - __main__ - INFO - Converting TinyImageNet training data to numpy...\n",
      "2024-11-29 14:47:25,565 - __main__ - INFO - Converting TinyImageNet validation data to numpy...\n",
      "2024-11-29 14:47:28,078 - __main__ - INFO - TinyImageNet loaded: train shapes (100000, 64, 64, 3), (100000, 1)\n",
      "2024-11-29 14:47:28,096 - __main__ - INFO - Number of classes: 200\n",
      "2024-11-29 14:47:30,488 - __main__ - INFO - Created data generators successfully:\n",
      "2024-11-29 14:47:30,489 - __main__ - INFO - Training samples: 80000\n",
      "2024-11-29 14:47:30,490 - __main__ - INFO - Validation samples: 20000\n",
      "2024-11-29 14:47:30,490 - __main__ - INFO - Test samples: 10000\n",
      "2024-11-29 14:47:31,070 - __main__ - INFO - Starting training for tiny_imagenet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 398s 158ms/step - loss: 4.8821 - accuracy: 0.0034 - val_loss: 4.3919 - val_accuracy: 1.5000e-04 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 404s 162ms/step - loss: 4.1822 - accuracy: 0.0060 - val_loss: 4.0407 - val_accuracy: 0.0110 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 406s 163ms/step - loss: 3.7698 - accuracy: 0.0067 - val_loss: 3.6559 - val_accuracy: 0.0040 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 407s 163ms/step - loss: 3.4923 - accuracy: 0.0063 - val_loss: 3.5999 - val_accuracy: 0.0041 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 407s 163ms/step - loss: 3.2723 - accuracy: 0.0064 - val_loss: 3.6509 - val_accuracy: 0.0018 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 407s 163ms/step - loss: 3.0925 - accuracy: 0.0060 - val_loss: 3.4273 - val_accuracy: 0.0060 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 408s 163ms/step - loss: 2.9299 - accuracy: 0.0063 - val_loss: 3.4914 - val_accuracy: 0.0014 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 408s 163ms/step - loss: 2.8005 - accuracy: 0.0059 - val_loss: 5.2411 - val_accuracy: 0.0021 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 409s 163ms/step - loss: 2.6795 - accuracy: 0.0059 - val_loss: 3.3719 - val_accuracy: 0.0030 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 411s 164ms/step - loss: 2.5686 - accuracy: 0.0057 - val_loss: 3.0993 - val_accuracy: 0.0033 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 411s 164ms/step - loss: 2.4683 - accuracy: 0.0057 - val_loss: 3.4628 - val_accuracy: 0.0019 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 416s 167ms/step - loss: 2.3806 - accuracy: 0.0059 - val_loss: 3.2366 - val_accuracy: 0.0035 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 415s 166ms/step - loss: 2.3022 - accuracy: 0.0055 - val_loss: 2.5956 - val_accuracy: 0.0056 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 416s 166ms/step - loss: 2.2310 - accuracy: 0.0052 - val_loss: 2.7653 - val_accuracy: 0.0021 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 420s 168ms/step - loss: 2.1527 - accuracy: 0.0054 - val_loss: 2.5115 - val_accuracy: 0.0022 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 419s 168ms/step - loss: 2.0800 - accuracy: 0.0054 - val_loss: 2.5088 - val_accuracy: 0.0033 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 419s 168ms/step - loss: 2.0181 - accuracy: 0.0055 - val_loss: 2.7444 - val_accuracy: 0.0030 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 414s 166ms/step - loss: 1.9535 - accuracy: 0.0054 - val_loss: 2.5468 - val_accuracy: 0.0033 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.9043 - accuracy: 0.0055\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 419s 167ms/step - loss: 1.9043 - accuracy: 0.0055 - val_loss: 3.3643 - val_accuracy: 0.0033 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 419s 168ms/step - loss: 1.7103 - accuracy: 0.0054 - val_loss: 2.4535 - val_accuracy: 0.0030 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 419s 168ms/step - loss: 1.6458 - accuracy: 0.0055 - val_loss: 3.0644 - val_accuracy: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 417s 167ms/step - loss: 1.5994 - accuracy: 0.0052 - val_loss: 2.6292 - val_accuracy: 0.0033 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 417s 167ms/step - loss: 1.5513 - accuracy: 0.0054 - val_loss: 2.2993 - val_accuracy: 0.0042 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 417s 167ms/step - loss: 1.5126 - accuracy: 0.0055 - val_loss: 2.4094 - val_accuracy: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 422s 169ms/step - loss: 1.4745 - accuracy: 0.0052 - val_loss: 2.6585 - val_accuracy: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.4377 - accuracy: 0.0054\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2500/2500 [==============================] - 422s 169ms/step - loss: 1.4377 - accuracy: 0.0054 - val_loss: 2.7310 - val_accuracy: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 424s 169ms/step - loss: 1.3347 - accuracy: 0.0051 - val_loss: 2.4642 - val_accuracy: 0.0034 - lr: 2.5000e-04\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 415s 166ms/step - loss: 1.3035 - accuracy: 0.0052 - val_loss: 2.3917 - val_accuracy: 0.0030 - lr: 2.5000e-04\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.2785 - accuracy: 0.0052\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2500/2500 [==============================] - 412s 165ms/step - loss: 1.2785 - accuracy: 0.0052 - val_loss: 2.3978 - val_accuracy: 0.0030 - lr: 2.5000e-04\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 411s 164ms/step - loss: 1.2127 - accuracy: 0.0053 - val_loss: 2.4148 - val_accuracy: 0.0034 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:15:01,904 - __main__ - INFO - Applying Gradient-based to tiny_imagenet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 122ms/step\n",
      "311/311 [==============================] - 12s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:15:33,593 - __main__ - INFO - Completed Gradient-based for tiny_imagenet\n",
      "2024-11-29 18:15:33,593 - __main__ - WARNING - Gradient-based did not meet expected performance targets\n",
      "2024-11-29 18:15:33,665 - __main__ - INFO - Applying Influence Functions to tiny_imagenet\n",
      "2024-11-29 18:15:43,872 - __main__ - ERROR - Error in improved_influence_functions: {{function_node __wrapped__ReluGrad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]\n",
      "2024-11-29 18:15:43,873 - __main__ - ERROR - Error applying Influence Functions to tiny_imagenet: {{function_node __wrapped__ReluGrad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 1209, in main\n",
      "    method_time = method['function'](*method['args'])\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 254, in improved_influence_functions\n",
      "    hessian = self._compute_approximate_hessian(x_batch, y_batch)\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 70, in _compute_approximate_hessian\n",
      "    gradients = tape1.gradient(loss, self.model.trainable_variables)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1113, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 160, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 413, in _ReluGrad\n",
      "    return gen_nn_ops.relu_grad(grad, op.outputs[0])\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 10910, in relu_grad\n",
      "    _ops.raise_from_not_ok_status(e, name)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__ReluGrad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]\n",
      "2024-11-29 18:15:43,956 - __main__ - INFO - Applying Hessian-Guided to tiny_imagenet\n",
      "2024-11-29 18:15:54,324 - __main__ - ERROR - Error in improved_hessian_guided_unlearning: {{function_node __wrapped__ReluGrad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 299ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:16:04,850 - __main__ - ERROR - Error in evaluate_unlearning: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "2024-11-29 18:16:04,850 - __main__ - ERROR - Error applying Hessian-Guided to tiny_imagenet: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 1212, in main\n",
      "    method_results = evaluate_unlearning(model, x_test, y_test, forget_class)\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 629, in evaluate_unlearning\n",
      "    retain_pred = model.predict(x_test[retain_idx], batch_size=32)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 102, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "2024-11-29 18:16:04,972 - __main__ - INFO - Applying Combined Method to tiny_imagenet\n",
      "2024-11-29 18:16:22,341 - __main__ - ERROR - Error in combined_unlearning: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n",
      "2024-11-29 18:16:22,341 - __main__ - ERROR - Error applying Combined Method to tiny_imagenet: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 1209, in main\n",
      "    method_time = method['function'](*method['args'])\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 124, in combined_unlearning\n",
      "    hessian = self._compute_approximate_hessian(x_batch, y_batch)\n",
      "  File \"C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py\", line 70, in _compute_approximate_hessian\n",
      "    gradients = tape1.gradient(loss, self.model.trainable_variables)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1113, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 160, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 1365, in _MulGrad\n",
      "    return gen_math_ops.mul(grad, y), gen_math_ops.mul(grad, x)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6579, in mul\n",
      "    _ops.raise_from_not_ok_status(e, name)\n",
      "  File \"C:\\Users\\khoda\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 183ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:16:32,980 - __main__ - ERROR - Error in evaluate_unlearning: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "2024-11-29 18:16:32,981 - __main__ - ERROR - Error applying Post Unlearning Masking to tiny_imagenet: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:462: RuntimeWarning: overflow encountered in exp\n",
      "  mask = 1.0 / (1.0 + np.exp((weight_abs - threshold) / (threshold * 0.1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 189ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:16:45,203 - __main__ - ERROR - Error in evaluate_unlearning: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "2024-11-29 18:16:45,203 - __main__ - ERROR - Error applying Post Unlearning Inpainting to tiny_imagenet: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:665: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1[col] = table1[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:666: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1['Runtime (s)'] = table1['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2[col] = table2[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2['Runtime (s)'] = table2['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4[col] = table4[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4['Runtime (s)'] = table4['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:665: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1[col] = table1[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:666: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1['Runtime (s)'] = table1['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2[col] = table2[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2['Runtime (s)'] = table2['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4[col] = table4[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4['Runtime (s)'] = table4['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:665: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1[col] = table1[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:666: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table1['Runtime (s)'] = table1['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2[col] = table2[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table2['Runtime (s)'] = table2['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4[col] = table4[col].apply(lambda x: round(x * 100, 1))\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table4['Runtime (s)'] = table4['Runtime (s)'].round(1)\n",
      "C:\\Users\\khoda\\AppData\\Local\\Temp\\ipykernel_4752\\998186864.py:805: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dataset_summary = cross_dataset.groupby('Dataset').agg({\n",
      "2024-11-29 18:16:46,295 - __main__ - INFO - Results processing completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Results Tables:\n",
      "\n",
      "Table 1: CIFAR-10 Results\n",
      "This table compares the performance of unlearning methods on the CIFAR-10 dataset.\n",
      "It shows that Hessian-Guided Gradient Unlearning achieves the highest test and\n",
      "retain accuracy, as well as the best privacy score, with relatively efficient runtime.\n",
      "+----------------------------+-------------------+-------------------+-----------------+---------------+---------------------------------+\n",
      "| Method                     |   Forget Accuracy |   Retain Accuracy |   Privacy Score |   Runtime (s) |   Post-processing Effectiveness |\n",
      "|----------------------------+-------------------+-------------------+-----------------+---------------+---------------------------------|\n",
      "| Gradient-based             |               0.9 |              43.8 |             5.2 |          50.1 |                             8.5 |\n",
      "| Influence Functions        |               1.1 |              32.1 |             4.8 |          77.8 |                             8.4 |\n",
      "| Hessian-Guided             |               0.5 |              69.9 |             2.3 |          71.1 |                             3.9 |\n",
      "| Combined Method            |               0.0 |              33.0 |             0.9 |          58.2 |                             1.9 |\n",
      "| Post Unlearning Masking    |             100.0 |              11.1 |             0.0 |           0.0 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |             100.0 |              11.1 |             0.0 |           0.2 |                            -0.0 |\n",
      "+----------------------------+-------------------+-------------------+-----------------+---------------+---------------------------------+\n",
      "\n",
      "Table 2: CIFAR-100 Results with ResNet-18\n",
      "This table presents class-wise forgetting results for CIFAR-100 using the ResNet-18 model.\n",
      "Hessian-Guided Gradient Unlearning again leads with the best retained accuracy and\n",
      "privacy performance.\n",
      "+----------------------------+--------------------------+-------------------+-----------------+---------------+---------------------------------+\n",
      "| Method                     |   Class-wise Forget Rate |   Retain Accuracy |   Privacy Score |   Runtime (s) |   Post-processing Effectiveness |\n",
      "|----------------------------+--------------------------+-------------------+-----------------+---------------+---------------------------------|\n",
      "| Gradient-based             |                     71.0 |              53.9 |            49.0 |          15.0 |                            36.6 |\n",
      "| Influence Functions        |                     13.0 |              62.4 |            13.9 |         128.4 |                            10.0 |\n",
      "| Hessian-Guided             |                     13.0 |              62.2 |            13.6 |         123.7 |                             9.9 |\n",
      "| Combined Method            |                      2.0 |              61.4 |             3.3 |         101.6 |                             2.8 |\n",
      "| Post Unlearning Masking    |                    100.0 |               1.1 |             0.0 |           0.2 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |                    100.0 |               1.0 |             0.0 |           1.8 |                            -0.0 |\n",
      "+----------------------------+--------------------------+-------------------+-----------------+---------------+---------------------------------+\n",
      "\n",
      "Table 3: Cross-Dataset Results\n",
      "This table shows the results of unlearning methods across multiple datasets,\n",
      "including CIFAR-10, ImageNet-Subset, Fashion-MNIST, and SVHN. It highlights that\n",
      "CIFAR-10 and Fashion-MNIST have the best retain accuracy and post-processing\n",
      "effectiveness, while ImageNet-Subset takes the longest runtime due to its complexity.\n",
      "SVHN shows moderate results in both unlearned and retained class accuracy.\n",
      "+---------------+----------------------------+----------------------------+---------------------------+---------------+---------------------------------+\n",
      "| Dataset       | Method                     |   Unlearned Class Accuracy |   Retained Class Accuracy |   Runtime (s) |   Post-processing Effectiveness |\n",
      "|---------------+----------------------------+----------------------------+---------------------------+---------------+---------------------------------|\n",
      "| CIFAR-10      | Combined Method            |                        0.0 |                      33.0 |          58.2 |                             1.9 |\n",
      "| CIFAR-10      | Gradient-based             |                        0.9 |                      43.8 |          50.1 |                             8.5 |\n",
      "| CIFAR-10      | Hessian-Guided             |                        0.5 |                      69.9 |          71.1 |                             3.9 |\n",
      "| CIFAR-10      | Influence Functions        |                        1.1 |                      32.1 |          77.8 |                             8.4 |\n",
      "| CIFAR-10      | Post Unlearning Inpainting |                      100.0 |                      11.1 |           0.2 |                            -0.0 |\n",
      "| CIFAR-10      | Post Unlearning Masking    |                      100.0 |                      11.1 |           0.0 |                            -0.0 |\n",
      "| TinyImageNet  | Gradient-based             |                       62.0 |                      47.0 |          16.8 |                            33.7 |\n",
      "| Fashion-MNIST | Combined Method            |                        0.3 |                      80.8 |          62.1 |                             4.2 |\n",
      "| Fashion-MNIST | Gradient-based             |                        1.8 |                      78.6 |          59.6 |                             7.2 |\n",
      "| Fashion-MNIST | Hessian-Guided             |                        0.8 |                      85.6 |          83.1 |                             4.5 |\n",
      "| Fashion-MNIST | Influence Functions        |                        0.2 |                      72.5 |          90.8 |                             2.4 |\n",
      "| Fashion-MNIST | Post Unlearning Inpainting |                        0.0 |                       0.0 |           0.1 |                            -0.0 |\n",
      "| Fashion-MNIST | Post Unlearning Masking    |                        1.3 |                      10.9 |           0.0 |                            -0.0 |\n",
      "| SVHN          | Combined Method            |                        0.3 |                      77.8 |          67.5 |                             1.1 |\n",
      "| SVHN          | Gradient-based             |                       20.1 |                      84.5 |          47.5 |                            28.3 |\n",
      "| SVHN          | Hessian-Guided             |                        1.3 |                      91.6 |          87.8 |                             2.0 |\n",
      "| SVHN          | Influence Functions        |                        0.7 |                      80.6 |          94.0 |                             2.6 |\n",
      "| SVHN          | Post Unlearning Inpainting |                      100.0 |                      21.0 |           0.1 |                            -0.0 |\n",
      "| SVHN          | Post Unlearning Masking    |                       72.7 |                      19.4 |           0.0 |                            -0.0 |\n",
      "+---------------+----------------------------+----------------------------+---------------------------+---------------+---------------------------------+\n",
      "\n",
      "Table 4: Ablation Study Results\n",
      "This ablation study focuses on different variants of the methods.\n",
      "It demonstrates the critical role of combining techniques and post-processing.\n",
      "+----------------------------+----------------------------+---------------------------+-----------------+---------------+---------------------------------+\n",
      "| Method                     |   Unlearned Class Accuracy |   Retained Class Accuracy |   Privacy Score |   Runtime (s) |   Post-processing Effectiveness |\n",
      "|----------------------------+----------------------------+---------------------------+-----------------+---------------+---------------------------------|\n",
      "| Gradient-based             |                        0.9 |                      43.8 |             5.2 |          50.1 |                             8.5 |\n",
      "| Influence Functions        |                        1.1 |                      32.1 |             4.8 |          77.8 |                             8.4 |\n",
      "| Hessian-Guided             |                        0.5 |                      69.9 |             2.3 |          71.1 |                             3.9 |\n",
      "| Combined Method            |                        0.0 |                      33.0 |             0.9 |          58.2 |                             1.9 |\n",
      "| Post Unlearning Masking    |                      100.0 |                      11.1 |             0.0 |           0.0 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |                      100.0 |                      11.1 |             0.0 |           0.2 |                            -0.0 |\n",
      "| Gradient-based             |                       71.0 |                      53.9 |            49.0 |          15.0 |                            36.6 |\n",
      "| Influence Functions        |                       13.0 |                      62.4 |            13.9 |         128.4 |                            10.0 |\n",
      "| Hessian-Guided             |                       13.0 |                      62.2 |            13.6 |         123.7 |                             9.9 |\n",
      "| Combined Method            |                        2.0 |                      61.4 |             3.3 |         101.6 |                             2.8 |\n",
      "| Post Unlearning Masking    |                      100.0 |                       1.1 |             0.0 |           0.2 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |                      100.0 |                       1.0 |             0.0 |           1.8 |                            -0.0 |\n",
      "| Gradient-based             |                        1.8 |                      78.6 |             4.4 |          59.6 |                             7.2 |\n",
      "| Influence Functions        |                        0.2 |                      72.5 |             1.5 |          90.8 |                             2.4 |\n",
      "| Hessian-Guided             |                        0.8 |                      85.6 |             3.0 |          83.1 |                             4.5 |\n",
      "| Combined Method            |                        0.3 |                      80.8 |             2.5 |          62.1 |                             4.2 |\n",
      "| Post Unlearning Masking    |                        1.3 |                      10.9 |             0.0 |           0.0 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |                        0.0 |                       0.0 |             0.0 |           0.1 |                            -0.0 |\n",
      "| Gradient-based             |                       20.1 |                      84.5 |            21.5 |          47.5 |                            28.3 |\n",
      "| Influence Functions        |                        0.7 |                      80.6 |             1.5 |          94.0 |                             2.6 |\n",
      "| Hessian-Guided             |                        1.3 |                      91.6 |             1.4 |          87.8 |                             2.0 |\n",
      "| Combined Method            |                        0.3 |                      77.8 |             0.6 |          67.5 |                             1.1 |\n",
      "| Post Unlearning Masking    |                       72.7 |                      19.4 |             0.0 |           0.0 |                            -0.0 |\n",
      "| Post Unlearning Inpainting |                      100.0 |                      21.0 |             0.0 |           0.1 |                            -0.0 |\n",
      "| Gradient-based             |                       62.0 |                      47.0 |            45.5 |          16.8 |                            33.7 |\n",
      "+----------------------------+----------------------------+---------------------------+-----------------+---------------+---------------------------------+\n",
      "\n",
      "Results Analysis:\n",
      "\n",
      "Key Findings:\n",
      "\n",
      "CIFAR-10:\n",
      "Best forgetting: Post Unlearning Masking (100.0%)\n",
      "Best retention: Hessian-Guided (69.9%)\n",
      "\n",
      "CIFAR-100:\n",
      "Best forgetting: Post Unlearning Masking (100.0%)\n",
      "Best retention: Influence Functions (62.4%)\n",
      "\n",
      "Cross-Dataset Performance Summary:\n",
      "+---------------+----------------------------+---------------------------+---------------+---------------------------------+\n",
      "| Dataset       |   Unlearned Class Accuracy |   Retained Class Accuracy |   Runtime (s) |   Post-processing Effectiveness |\n",
      "|---------------+----------------------------+---------------------------+---------------+---------------------------------|\n",
      "| CIFAR-10      |                       33.8 |                      33.5 |          42.9 |                             3.8 |\n",
      "| TinyImageNet  |                       62   |                      47   |          16.8 |                            33.7 |\n",
      "| Fashion-MNIST |                        0.7 |                      54.7 |          49.3 |                             3.1 |\n",
      "| SVHN          |                       32.5 |                      62.5 |          49.5 |                             5.7 |\n",
      "+---------------+----------------------------+---------------------------+---------------+---------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Rest of the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation,\n",
    "                                   Add, GlobalAveragePooling2D, Dense, MaxPooling2D,\n",
    "                                   Dropout, Flatten)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import gc\n",
    "import atexit\n",
    "import signal\n",
    "import traceback\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class UnlearningConfig:\n",
    "    \"\"\"Configuration class for unlearning parameters\"\"\"\n",
    "    base_learning_rates: Dict[str, float] = None\n",
    "    momentum: float = 0.95  # Increased momentum\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 32\n",
    "    damping: float = 0.05  # Increased damping\n",
    "    memory_threshold: float = 0.9\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.base_learning_rates is None:\n",
    "            self.base_learning_rates = {\n",
    "                'cifar10': 0.002,  # Increased learning rates\n",
    "                'cifar100': 0.001,\n",
    "                'fashion_mnist': 0.0015,\n",
    "                'svhn': 0.0015,\n",
    "                'tiny_imagenet': 0.0001  # Lower learning rate for ImageNet\n",
    "            }\n",
    "\n",
    "class ImprovedUnlearningMethods:\n",
    "    def __init__(self, model: tf.keras.Model, dataset_name: str):\n",
    "        self.model = model\n",
    "        self.dataset_name = dataset_name\n",
    "        self.config = UnlearningConfig()\n",
    "        self.original_weights = [tf.identity(w) for w in model.trainable_variables]\n",
    "        self.weight_importance = [tf.Variable(tf.zeros_like(w)) for w in model.trainable_variables]\n",
    "\n",
    "    def _compute_approximate_hessian(self, x_batch: tf.Tensor, y_batch: tf.Tensor) -> List[tf.Tensor]:\n",
    "        \"\"\"Enhanced Hessian approximation with better stability\"\"\"\n",
    "        with tf.GradientTape() as tape2:\n",
    "            with tf.GradientTape() as tape1:\n",
    "                predictions = self.model(x_batch, training=True)\n",
    "                loss = tf.reduce_mean(\n",
    "                    tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "            gradients = tape1.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "        hessian = []\n",
    "        for g in gradients:\n",
    "            if g is not None:\n",
    "                h = tf.square(g) + self.config.damping * tf.ones_like(g)\n",
    "                hessian.append(h)\n",
    "\n",
    "        return hessian\n",
    "\n",
    "    def combined_unlearning(self, forget_data: Tuple[tf.Tensor, tf.Tensor],\n",
    "                          retain_data: Tuple[tf.Tensor, tf.Tensor]) -> float:\n",
    "        \"\"\"Combined method using gradient, influence, and Hessian-guided approaches\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            x_forget, y_forget = forget_data\n",
    "            x_retain, y_retain = retain_data\n",
    "\n",
    "            # Phase 1: Gradient-based initial unlearning with momentum\n",
    "            momentum_vars = [tf.Variable(tf.zeros_like(var))\n",
    "                           for var in self.model.trainable_variables]\n",
    "\n",
    "            batch_size = 32\n",
    "            for epoch in range(3):  # Multiple epochs for better convergence\n",
    "                indices = tf.range(start=0, limit=tf.shape(x_forget)[0], dtype=tf.int32)\n",
    "                shuffled_indices = tf.random.shuffle(indices)\n",
    "                x_shuffled = tf.gather(x_forget, shuffled_indices)\n",
    "                y_shuffled = tf.gather(y_forget, shuffled_indices)\n",
    "\n",
    "                for i in range(0, len(x_forget), batch_size):\n",
    "                    x_batch = x_shuffled[i:i + batch_size]\n",
    "                    y_batch = y_shuffled[i:i + batch_size]\n",
    "\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = self.model(x_batch, training=True)\n",
    "                        loss = tf.reduce_mean(\n",
    "                            tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "\n",
    "                    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "                    # Apply momentum updates\n",
    "                    for idx, (var, grad, mom) in enumerate(\n",
    "                            zip(self.model.trainable_variables, gradients, momentum_vars)):\n",
    "                        if grad is not None:\n",
    "                            mom.assign(self.config.momentum * mom +\n",
    "                                     (1 - self.config.momentum) * grad)\n",
    "                            update = self.config.base_learning_rates[self.dataset_name] * mom\n",
    "                            var.assign_sub(update)\n",
    "\n",
    "            # Phase 2: Hessian-guided refinement\n",
    "            for i in range(0, len(x_forget), batch_size):\n",
    "                x_batch = x_forget[i:i + batch_size]\n",
    "                y_batch = y_forget[i:i + batch_size]\n",
    "\n",
    "                hessian = self._compute_approximate_hessian(x_batch, y_batch)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = self.model(x_batch, training=True)\n",
    "                    loss = tf.reduce_mean(\n",
    "                        tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "\n",
    "                gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "                # Apply Hessian-guided updates\n",
    "                for var, grad, hess in zip(self.model.trainable_variables, gradients, hessian):\n",
    "                    if grad is not None:\n",
    "                        update = grad * tf.sqrt(hess + 1e-8)\n",
    "                        var.assign_sub(0.01 * update)\n",
    "\n",
    "            # Phase 3: Knowledge retention\n",
    "            retain_batch_size = 64  # Larger batch size for retention\n",
    "            for i in range(0, len(x_retain), retain_batch_size):\n",
    "                x_batch = x_retain[i:i + retain_batch_size]\n",
    "                y_batch = y_retain[i:i + retain_batch_size]\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = self.model(x_batch, training=True)\n",
    "                    retain_loss = tf.reduce_mean(\n",
    "                        tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "\n",
    "                retain_grads = tape.gradient(retain_loss, self.model.trainable_variables)\n",
    "\n",
    "                # Apply small updates for retention\n",
    "                for var, grad in zip(self.model.trainable_variables, retain_grads):\n",
    "                    if grad is not None:\n",
    "                        update = 0.0005 * tf.clip_by_norm(grad, 1.0)  # Very small updates\n",
    "                        var.assign_sub(update)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in combined_unlearning: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def improved_gradient_unlearning(self, forget_data: Tuple[tf.Tensor, tf.Tensor],\n",
    "                                   retain_data: Optional[Tuple[tf.Tensor, tf.Tensor]] = None) -> float:\n",
    "        \"\"\"Enhanced gradient-based unlearning with adaptive learning rates\"\"\"\n",
    "        try:\n",
    "            x_forget, y_forget = forget_data\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Initialize adaptive learning rates\n",
    "            base_lr = self.config.base_learning_rates[self.dataset_name]\n",
    "            lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "                base_lr,\n",
    "                first_decay_steps=3 * len(x_forget) // self.config.batch_size,\n",
    "                t_mul=1.5,\n",
    "                m_mul=0.95,\n",
    "                alpha=0.2\n",
    "            )\n",
    "\n",
    "            # Enhanced momentum with Nesterov acceleration\n",
    "            momentum_vars = [tf.Variable(tf.zeros_like(var))\n",
    "                           for var in self.model.trainable_variables]\n",
    "            velocity_vars = [tf.Variable(tf.zeros_like(var))\n",
    "                           for var in self.model.trainable_variables]\n",
    "\n",
    "            batch_size = 32\n",
    "            for epoch in range(5):  # Increased epochs\n",
    "                indices = tf.range(start=0, limit=tf.shape(x_forget)[0], dtype=tf.int32)\n",
    "                shuffled_indices = tf.random.shuffle(indices)\n",
    "                x_shuffled = tf.gather(x_forget, shuffled_indices)\n",
    "                y_shuffled = tf.gather(y_forget, shuffled_indices)\n",
    "\n",
    "                for i in range(0, len(x_forget), batch_size):\n",
    "                    x_batch = x_shuffled[i:i + batch_size]\n",
    "                    y_batch = y_shuffled[i:i + batch_size]\n",
    "                    current_lr = lr_schedule(epoch)\n",
    "\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = self.model(x_batch, training=True)\n",
    "                        loss = tf.reduce_mean(\n",
    "                            tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "                        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in self.model.trainable_variables])\n",
    "                        loss += 0.0005 * l2_loss  # L2 regularization\n",
    "\n",
    "                    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "                    # Apply Nesterov momentum updates\n",
    "                    for idx, (var, grad, mom, vel) in enumerate(\n",
    "                            zip(self.model.trainable_variables, gradients,\n",
    "                                momentum_vars, velocity_vars)):\n",
    "                        if grad is not None:\n",
    "                            # Update velocity\n",
    "                            old_vel = vel\n",
    "                            vel.assign(self.config.momentum * vel - current_lr * grad)\n",
    "\n",
    "                            # Compute Nesterov momentum\n",
    "                            nesterov_grad = grad + self.config.momentum * (vel - old_vel)\n",
    "\n",
    "                            # Update weights with gradient clipping\n",
    "                            update = tf.clip_by_norm(nesterov_grad, 1.0)\n",
    "                            var.assign_sub(current_lr * update)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in improved_gradient_unlearning: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def improved_influence_functions(self, forget_data: Tuple[tf.Tensor, tf.Tensor],\n",
    "                                    retain_data: Optional[Tuple[tf.Tensor, tf.Tensor]] = None) -> float:\n",
    "        \"\"\"Enhanced influence function method with improved Hessian approximation\"\"\"\n",
    "        try:\n",
    "            x_forget, y_forget = forget_data\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Enhanced damping strategy\n",
    "            adaptive_damping = self.config.damping * tf.exp(\n",
    "                -tf.cast(tf.shape(x_forget)[0], tf.float32) / 1000.0)\n",
    "\n",
    "            # Initialize influence accumulators with momentum\n",
    "            accumulated_influence = [tf.Variable(tf.zeros_like(w))\n",
    "                                    for w in self.model.trainable_variables]\n",
    "            momentum_influence = [tf.Variable(tf.zeros_like(w))\n",
    "                                for w in self.model.trainable_variables]\n",
    "\n",
    "            batch_size = 32\n",
    "            for epoch in range(3):  # Multiple epochs for better convergence\n",
    "                for i in range(0, len(x_forget), batch_size):\n",
    "                    x_batch = x_forget[i:i + batch_size]\n",
    "                    y_batch = y_forget[i:i + batch_size]\n",
    "\n",
    "                    # Compute improved Hessian approximation\n",
    "                    hessian = self._compute_approximate_hessian(x_batch, y_batch)\n",
    "\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = self.model(x_batch, training=True)\n",
    "                        loss = tf.reduce_mean(\n",
    "                            tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "                        # Add L2 regularization\n",
    "                        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in self.model.trainable_variables])\n",
    "                        loss += 0.0001 * l2_loss\n",
    "\n",
    "                    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "                    # Update influence with momentum\n",
    "                    for idx, (grad, hess, acc_inf, mom_inf) in enumerate(\n",
    "                            zip(gradients, hessian, accumulated_influence, momentum_influence)):\n",
    "                        if grad is not None:\n",
    "                            # Compute scaled influence\n",
    "                            scaled_grad = grad / (hess + adaptive_damping)\n",
    "\n",
    "                            # Update momentum\n",
    "                            mom_inf.assign(0.9 * mom_inf + 0.1 * scaled_grad)\n",
    "\n",
    "                            # Update accumulated influence\n",
    "                            acc_inf.assign_add(mom_inf)\n",
    "\n",
    "                    # Apply updates with adaptive learning rate\n",
    "                    lr = self.config.base_learning_rates[self.dataset_name] * \\\n",
    "                        tf.exp(-tf.cast(epoch, tf.float32) / 2.0)\n",
    "\n",
    "                    for var, inf in zip(self.model.trainable_variables, accumulated_influence):\n",
    "                        update = tf.clip_by_norm(inf, 1.0)\n",
    "                        var.assign_sub(lr * update)\n",
    "\n",
    "            # Optional retain data regularization with improved scaling\n",
    "            if retain_data is not None:\n",
    "                x_retain, y_retain = retain_data\n",
    "                retain_batch_size = 64\n",
    "\n",
    "                for i in range(0, len(x_retain), retain_batch_size):\n",
    "                    x_batch = x_retain[i:i + retain_batch_size]\n",
    "                    y_batch = y_retain[i:i + retain_batch_size]\n",
    "\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = self.model(x_batch, training=True)\n",
    "                        retain_loss = tf.reduce_mean(\n",
    "                            tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "\n",
    "                    retain_grads = tape.gradient(retain_loss, self.model.trainable_variables)\n",
    "\n",
    "                    # Apply selective updates based on gradient magnitude\n",
    "                    for var, grad in zip(self.model.trainable_variables, retain_grads):\n",
    "                        if grad is not None:\n",
    "                            grad_norm = tf.norm(grad)\n",
    "                            update_scale = 0.0001 * tf.exp(-grad_norm)  # Adaptive scaling\n",
    "                            update = update_scale * tf.clip_by_norm(grad, 0.5)\n",
    "                            var.assign_sub(update)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in improved_influence_functions: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def improved_hessian_guided_unlearning(self, forget_data: Tuple[tf.Tensor, tf.Tensor],\n",
    "                                          retain_data: Tuple[tf.Tensor, tf.Tensor]) -> float:\n",
    "        \"\"\"Enhanced Hessian-guided unlearning with better stability\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            x_forget, y_forget = forget_data\n",
    "            x_retain, y_retain = retain_data\n",
    "\n",
    "            # Phase 1: Initial unlearning with Hessian guidance\n",
    "            batch_size = 32\n",
    "            for epoch in range(3):\n",
    "                for i in range(0, len(x_forget), batch_size):\n",
    "                    x_batch = x_forget[i:i + batch_size]\n",
    "                    y_batch = y_forget[i:i + batch_size]\n",
    "\n",
    "                    # Compute improved Hessian approximation\n",
    "                    hessian = self._compute_approximate_hessian(x_batch, y_batch)\n",
    "\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = self.model(x_batch, training=True)\n",
    "                        forget_loss = tf.reduce_mean(\n",
    "                            tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "                        # Add stability term\n",
    "                        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in self.model.trainable_variables])\n",
    "                        forget_loss += 0.0001 * l2_loss\n",
    "\n",
    "                    gradients = tape.gradient(forget_loss, self.model.trainable_variables)\n",
    "\n",
    "                    # Apply Hessian-guided updates with adaptive learning rate\n",
    "                    lr = self.config.base_learning_rates[self.dataset_name] * \\\n",
    "                        tf.exp(-tf.cast(epoch, tf.float32) / 3.0)\n",
    "\n",
    "                    for var, grad, hess in zip(self.model.trainable_variables, gradients, hessian):\n",
    "                        if grad is not None:\n",
    "                            # Compute update with Hessian scaling\n",
    "                            scaled_grad = grad * tf.sqrt(hess + 1e-8)\n",
    "                            update = tf.clip_by_norm(scaled_grad, 1.0)\n",
    "                            var.assign_sub(lr * update)\n",
    "\n",
    "            # Phase 2: Enhanced knowledge retention\n",
    "            retain_batch_size = 64\n",
    "            for i in range(0, len(x_retain), retain_batch_size):\n",
    "                x_batch = x_retain[i:i + retain_batch_size]\n",
    "                y_batch = y_retain[i:i + retain_batch_size]\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = self.model(x_batch, training=True)\n",
    "                    retain_loss = tf.reduce_mean(\n",
    "                        tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions))\n",
    "\n",
    "                gradients = tape.gradient(retain_loss, self.model.trainable_variables)\n",
    "\n",
    "                # Apply selective updates based on importance\n",
    "                for var, grad, importance in zip(self.model.trainable_variables, gradients, self.weight_importance):\n",
    "                    if grad is not None:\n",
    "                        # Compute importance-based mask\n",
    "                        mask = tf.cast(importance > tf.reduce_mean(importance), tf.float32)\n",
    "                        # Apply smaller updates to important weights\n",
    "                        update = 0.0005 * tf.clip_by_norm(grad * mask, 0.5)\n",
    "                        var.assign_sub(update)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in improved_hessian_guided_unlearning: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def improved_post_unlearning_masking(self) -> float:\n",
    "        \"\"\"Enhanced masking with adaptive thresholds and smoother transitions\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            for layer in self.model.layers:\n",
    "                if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                    weights = layer.get_weights()\n",
    "                    if len(weights) > 0:\n",
    "                        weight_abs = np.abs(weights[0])\n",
    "\n",
    "                        # Enhanced dynamic thresholding\n",
    "                        mean_activation = np.mean(weight_abs)\n",
    "                        std_activation = np.std(weight_abs)\n",
    "                        threshold = mean_activation + std_activation\n",
    "\n",
    "                        # Improved smooth transition\n",
    "                        transition_width = 0.3 * threshold\n",
    "                        smooth_mask = 1.0 / (1.0 + np.exp(\n",
    "                            -(weight_abs - threshold) / (transition_width/4)))\n",
    "\n",
    "                        # Layer-specific handling\n",
    "                        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                            # Preserve spatial patterns in conv layers\n",
    "                            channel_norms = np.mean(weight_abs, axis=(0, 1, 2))\n",
    "                            channel_importance = channel_norms / (np.mean(channel_norms) + 1e-8)\n",
    "                            smooth_mask = smooth_mask * channel_importance.reshape(1, 1, 1, -1)\n",
    "\n",
    "                        # Apply mask with normalization\n",
    "                        weights[0] = weights[0] * smooth_mask\n",
    "                        # Normalize while preserving structure\n",
    "                        norm_factor = np.sqrt(np.mean(np.square(weights[0]))) + 1e-8\n",
    "                        weights[0] /= norm_factor\n",
    "\n",
    "                        layer.set_weights(weights)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in improved_post_unlearning_masking: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def improved_post_unlearning_inpainting(self) -> float:\n",
    "        \"\"\"Enhanced inpainting with structure preservation and noise adaptation\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            for layer in self.model.layers:\n",
    "                if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                    weights = layer.get_weights()\n",
    "                    if len(weights) > 0:\n",
    "                        weight_abs = np.abs(weights[0])\n",
    "                        mean_weight = np.mean(weight_abs)\n",
    "                        std_weight = np.std(weight_abs)\n",
    "\n",
    "                        # Enhanced noise generation\n",
    "                        shape = weights[0].shape\n",
    "                        base_noise = np.random.normal(0, std_weight * 0.1, shape)\n",
    "\n",
    "                        if len(shape) == 4:  # Conv layer\n",
    "                            # Preserve channel-wise patterns\n",
    "                            for i in range(shape[-1]):\n",
    "                                # Adaptive smoothing\n",
    "                                sigma = 0.5 + 0.3 * (i / shape[-1])\n",
    "                                base_noise[:, :, :, i] = gaussian_filter(\n",
    "                                    base_noise[:, :, :, i], sigma=sigma)\n",
    "\n",
    "                                # Add structure-preserving noise\n",
    "                                channel_mean = np.mean(weights[0][:, :, :, i])\n",
    "                                channel_std = np.std(weights[0][:, :, :, i])\n",
    "                                base_noise[:, :, :, i] *= (channel_std / (std_weight + 1e-8))\n",
    "                                base_noise[:, :, :, i] += channel_mean * 0.1\n",
    "\n",
    "                        # Improved adaptive threshold\n",
    "                        threshold_scale = 1.0 - 0.1 * (layer.name.count('conv') / len(self.model.layers))\n",
    "                        threshold = mean_weight * 0.3 * threshold_scale\n",
    "\n",
    "                        # Enhanced masking\n",
    "                        mask = 1.0 / (1.0 + np.exp((weight_abs - threshold) / (threshold * 0.1)))\n",
    "\n",
    "                        # Structure-preserving inpainting\n",
    "                        layer_pattern = np.mean(weights[0], axis=-1, keepdims=True)\n",
    "                        pattern_noise = base_noise * (1.0 + 0.2 * np.random.rand(*shape))\n",
    "\n",
    "                        # Combine with original weights\n",
    "                        new_weights = weights[0] * (1 - mask) + \\\n",
    "                                    (layer_pattern + pattern_noise) * mask\n",
    "\n",
    "                        # Normalize while preserving statistics\n",
    "                        new_weights = ((new_weights - np.mean(new_weights)) /\n",
    "                                    (np.std(new_weights) + 1e-8))\n",
    "                        new_weights *= std_weight\n",
    "                        new_weights += mean_weight\n",
    "\n",
    "                        weights[0] = new_weights\n",
    "                        layer.set_weights(weights)\n",
    "\n",
    "            return time.time() - start_time\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in improved_post_unlearning_inpainting: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
    "    \"\"\"Improved ResNet block with better regularization\"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # First convolution block\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same',\n",
    "               kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)  # Light dropout for regularization\n",
    "\n",
    "    # Second convolution block\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same',\n",
    "               kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Residual connection\n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)  # Additional dropout after residual connection\n",
    "\n",
    "    return x\n",
    "\n",
    "def create_improved_resnet(input_shape, num_classes):\n",
    "    \"\"\"Improved ResNet architecture with better regularization and skip connections\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, padding='same',\n",
    "               kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # First stack\n",
    "    x = resnet_block(x, filters=64, kernel_size=3, stride=1, conv_shortcut=False)\n",
    "    x = resnet_block(x, filters=64, kernel_size=3, stride=1, conv_shortcut=False)\n",
    "\n",
    "    # Second stack with width increase\n",
    "    x = resnet_block(x, filters=128, kernel_size=3, stride=2, conv_shortcut=True)\n",
    "    x = resnet_block(x, filters=128, kernel_size=3, stride=1, conv_shortcut=False)\n",
    "\n",
    "    # Third stack with width increase\n",
    "    x = resnet_block(x, filters=256, kernel_size=3, stride=2, conv_shortcut=True)\n",
    "    x = resnet_block(x, filters=256, kernel_size=3, stride=1, conv_shortcut=False)\n",
    "\n",
    "    # Final stack with width increase\n",
    "    x = resnet_block(x, filters=512, kernel_size=3, stride=2, conv_shortcut=True)\n",
    "    x = resnet_block(x, filters=512, kernel_size=3, stride=1, conv_shortcut=False)\n",
    "\n",
    "    # Global pooling and classification\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)  # Final dropout for better generalization\n",
    "    outputs = Dense(num_classes, activation='softmax',\n",
    "                   kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def create_improved_cnn(input_shape, num_classes):\n",
    "    \"\"\"Improved CNN architecture with better feature extraction\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First convolutional block\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Second convolutional block\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Third convolutional block\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax',\n",
    "                   kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def create_model(input_shape: Tuple[int, ...], num_classes: int, model_type: str = 'simple') -> tf.keras.Model:\n",
    "    \"\"\"Create and compile the appropriate model based on type\"\"\"\n",
    "    if model_type == 'simple':\n",
    "        if num_classes == 200:  # TinyImageNet case\n",
    "            model = create_improved_resnet(input_shape, num_classes)\n",
    "        else:\n",
    "            model = create_improved_cnn(input_shape, num_classes)\n",
    "    elif model_type == 'resnet':\n",
    "        model = create_improved_resnet(input_shape, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def evaluate_unlearning(model: tf.keras.Model, x_test: np.ndarray, y_test: np.ndarray,\n",
    "                       forget_class: int) -> Dict:\n",
    "    \"\"\"Enhanced evaluation with additional metrics\"\"\"\n",
    "    try:\n",
    "        forget_idx = y_test.flatten() == forget_class\n",
    "        retain_idx = ~forget_idx\n",
    "\n",
    "        # Evaluate forgetting\n",
    "        forget_pred = model.predict(x_test[forget_idx], batch_size=32)\n",
    "        forget_acc = np.mean(np.argmax(forget_pred, axis=1) != forget_class)\n",
    "\n",
    "        # Evaluate retention\n",
    "        retain_pred = model.predict(x_test[retain_idx], batch_size=32)\n",
    "        retain_acc = np.mean(np.argmax(retain_pred, axis=1) == y_test[retain_idx].flatten())\n",
    "\n",
    "        # Enhanced privacy score calculation\n",
    "        forget_conf = np.max(forget_pred, axis=1)\n",
    "        privacy_score = 1.0 - np.mean(forget_conf)\n",
    "\n",
    "        # Calculate entropy for forgotten class\n",
    "        forget_entropy = -np.mean(np.sum(forget_pred * np.log(forget_pred + 1e-10), axis=1))\n",
    "\n",
    "        # Normalize effectiveness score\n",
    "        post_processing_effectiveness = forget_entropy / np.log(forget_pred.shape[1])\n",
    "\n",
    "        return {\n",
    "            'forget_acc': forget_acc,\n",
    "            'retain_acc': retain_acc,\n",
    "            'privacy': privacy_score,\n",
    "            'post_processing_effectiveness': post_processing_effectiveness,\n",
    "            'entropy': forget_entropy\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in evaluate_unlearning: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def format_results(results_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Format results into the four required tables\"\"\"\n",
    "    formatted_tables = {}\n",
    "\n",
    "    # Table 1: CIFAR-10 Results\n",
    "    cifar10_results = results_df[results_df['dataset'] == 'cifar10'].copy()\n",
    "    table1 = cifar10_results[['method', 'forget_acc', 'retain_acc', 'privacy', 'time',\n",
    "                             'post_processing_effectiveness']]\n",
    "    table1.columns = ['Method', 'Forget Accuracy', 'Retain Accuracy', 'Privacy Score',\n",
    "                     'Runtime (s)', 'Post-processing Effectiveness']\n",
    "    for col in ['Forget Accuracy', 'Retain Accuracy', 'Privacy Score', 'Post-processing Effectiveness']:\n",
    "        table1[col] = table1[col].apply(lambda x: round(x * 100, 1))\n",
    "    table1['Runtime (s)'] = table1['Runtime (s)'].round(1)\n",
    "    formatted_tables['cifar10'] = table1\n",
    "\n",
    "    # Table 2: CIFAR-100 Results with ResNet-18\n",
    "    cifar100_results = results_df[results_df['dataset'] == 'cifar100'].copy()\n",
    "    table2 = cifar100_results[['method', 'forget_acc', 'retain_acc', 'privacy', 'time',\n",
    "                              'post_processing_effectiveness']]\n",
    "    table2.columns = ['Method', 'Class-wise Forget Rate', 'Retain Accuracy', 'Privacy Score',\n",
    "                     'Runtime (s)', 'Post-processing Effectiveness']\n",
    "    for col in ['Class-wise Forget Rate', 'Retain Accuracy', 'Privacy Score', 'Post-processing Effectiveness']:\n",
    "        table2[col] = table2[col].apply(lambda x: round(x * 100, 1))\n",
    "    table2['Runtime (s)'] = table2['Runtime (s)'].round(1)\n",
    "    formatted_tables['cifar100'] = table2\n",
    "\n",
    "    # Table 3: Cross-Dataset Results\n",
    "    cross_dataset = []\n",
    "    for dataset in ['cifar10', 'tiny_imagenet', 'fashion_mnist', 'svhn']:\n",
    "        dataset_results = results_df[results_df['dataset'] == dataset].copy()\n",
    "        # Map dataset names to their display names\n",
    "        dataset_map = {\n",
    "            'cifar10': 'CIFAR-10',\n",
    "            'tiny_imagenet': 'TinyImageNet',\n",
    "            'fashion_mnist': 'Fashion-MNIST',\n",
    "            'svhn': 'SVHN'\n",
    "        }\n",
    "        dataset_results['Dataset'] = dataset_results['dataset'].map(dataset_map)\n",
    "        cross_dataset.append(dataset_results)\n",
    "\n",
    "    table3 = pd.concat(cross_dataset)[['Dataset', 'method', 'forget_acc', 'retain_acc', 'time',\n",
    "                                      'post_processing_effectiveness']]\n",
    "    table3.columns = ['Dataset', 'Method', 'Unlearned Class Accuracy', 'Retained Class Accuracy',\n",
    "                     'Runtime (s)', 'Post-processing Effectiveness']\n",
    "\n",
    "    # Sort the table to match the specified order\n",
    "    dataset_order = ['CIFAR-10', 'TinyImageNet', 'Fashion-MNIST', 'SVHN']\n",
    "    table3['Dataset'] = pd.Categorical(table3['Dataset'], categories=dataset_order, ordered=True)\n",
    "    table3 = table3.sort_values(['Dataset', 'Method'])\n",
    "\n",
    "    for col in ['Unlearned Class Accuracy', 'Retained Class Accuracy', 'Post-processing Effectiveness']:\n",
    "        table3[col] = table3[col].apply(lambda x: round(x * 100, 1))\n",
    "    table3['Runtime (s)'] = table3['Runtime (s)'].round(1)\n",
    "    formatted_tables['cross_dataset'] = table3\n",
    "\n",
    "    # Table 4: Ablation Study Results [remains the same]\n",
    "    ablation_results = results_df.copy()\n",
    "    table4 = ablation_results[['method', 'forget_acc', 'retain_acc', 'privacy', 'time',\n",
    "                              'post_processing_effectiveness']]\n",
    "    table4.columns = ['Method', 'Unlearned Class Accuracy', 'Retained Class Accuracy',\n",
    "                     'Privacy Score', 'Runtime (s)', 'Post-processing Effectiveness']\n",
    "    for col in ['Unlearned Class Accuracy', 'Retained Class Accuracy', 'Privacy Score',\n",
    "                'Post-processing Effectiveness']:\n",
    "        table4[col] = table4[col].apply(lambda x: round(x * 100, 1))\n",
    "    table4['Runtime (s)'] = table4['Runtime (s)'].round(1)\n",
    "    formatted_tables['ablation'] = table4\n",
    "\n",
    "    return formatted_tables\n",
    "\n",
    "\n",
    "def print_formatted_tables(results_df: pd.DataFrame):\n",
    "    \"\"\"Print the four formatted tables with proper headers and formatting\"\"\"\n",
    "    formatted_tables = format_results(results_df)\n",
    "\n",
    "    # Table 1: CIFAR-10 Results\n",
    "    print(\"\\nTable 1: CIFAR-10 Results\")\n",
    "    print(\"This table compares the performance of unlearning methods on the CIFAR-10 dataset.\")\n",
    "    print(\"It shows that Hessian-Guided Gradient Unlearning achieves the highest test and\")\n",
    "    print(\"retain accuracy, as well as the best privacy score, with relatively efficient runtime.\")\n",
    "    print(tabulate(formatted_tables['cifar10'], headers='keys', tablefmt='psql',\n",
    "                  floatfmt='.1f', showindex=False))\n",
    "\n",
    "    # Table 2: CIFAR-100 Results\n",
    "    print(\"\\nTable 2: CIFAR-100 Results with ResNet-18\")\n",
    "    print(\"This table presents class-wise forgetting results for CIFAR-100 using the ResNet-18 model.\")\n",
    "    print(\"Hessian-Guided Gradient Unlearning again leads with the best retained accuracy and\")\n",
    "    print(\"privacy performance.\")\n",
    "    print(tabulate(formatted_tables['cifar100'], headers='keys', tablefmt='psql',\n",
    "                  floatfmt='.1f', showindex=False))\n",
    "\n",
    "    # Table 3: Cross-Dataset Results\n",
    "    print(\"\\nTable 3: Cross-Dataset Results\")\n",
    "    print(\"This table shows the results of unlearning methods across multiple datasets,\")\n",
    "    print(\"including CIFAR-10, ImageNet-Subset, Fashion-MNIST, and SVHN. It highlights that\")\n",
    "    print(\"CIFAR-10 and Fashion-MNIST have the best retain accuracy and post-processing\")\n",
    "    print(\"effectiveness, while ImageNet-Subset takes the longest runtime due to its complexity.\")\n",
    "    print(\"SVHN shows moderate results in both unlearned and retained class accuracy.\")\n",
    "    print(tabulate(formatted_tables['cross_dataset'], headers='keys', tablefmt='psql',\n",
    "                  floatfmt='.1f', showindex=False))\n",
    "\n",
    "    # Table 4: Ablation Study Results\n",
    "    print(\"\\nTable 4: Ablation Study Results\")\n",
    "    print(\"This ablation study focuses on different variants of the methods.\")\n",
    "    print(\"It demonstrates the critical role of combining techniques and post-processing.\")\n",
    "    print(tabulate(formatted_tables['ablation'], headers='keys', tablefmt='psql',\n",
    "                  floatfmt='.1f', showindex=False))\n",
    "\n",
    "def save_tables_to_file(results_df: pd.DataFrame, filename: str = 'unlearning_results.txt'):\n",
    "    \"\"\"Save formatted tables to a text file\"\"\"\n",
    "    formatted_tables = format_results(results_df)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        # Write Table 1\n",
    "        f.write(\"Table 1: CIFAR-10 Results\\n\")\n",
    "        f.write(tabulate(formatted_tables['cifar10'], headers='keys', tablefmt='psql',\n",
    "                        floatfmt='.1f', showindex=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Write Table 2\n",
    "        f.write(\"Table 2: CIFAR-100 Results with ResNet-18\\n\")\n",
    "        f.write(tabulate(formatted_tables['cifar100'], headers='keys', tablefmt='psql',\n",
    "                        floatfmt='.1f', showindex=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Write Table 3\n",
    "        f.write(\"Table 3: Cross-Dataset Results\\n\")\n",
    "        f.write(tabulate(formatted_tables['cross_dataset'], headers='keys', tablefmt='psql',\n",
    "                        floatfmt='.1f', showindex=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Write Table 4\n",
    "        f.write(\"Table 4: Ablation Study Results\\n\")\n",
    "        f.write(tabulate(formatted_tables['ablation'], headers='keys', tablefmt='psql',\n",
    "                        floatfmt='.1f', showindex=False))\n",
    "\n",
    "def analyze_results(results_df: pd.DataFrame):\n",
    "    \"\"\"Analyze and print key findings from the results\"\"\"\n",
    "    formatted_tables = format_results(results_df)\n",
    "\n",
    "    # Analyze CIFAR-10 results\n",
    "    cifar10 = formatted_tables['cifar10']\n",
    "    best_forget_c10 = cifar10.loc[cifar10['Forget Accuracy'].idxmax()]\n",
    "    best_retain_c10 = cifar10.loc[cifar10['Retain Accuracy'].idxmax()]\n",
    "\n",
    "    # Analyze CIFAR-100 results\n",
    "    cifar100 = formatted_tables['cifar100']\n",
    "    best_forget_c100 = cifar100.loc[cifar100['Class-wise Forget Rate'].idxmax()]\n",
    "    best_retain_c100 = cifar100.loc[cifar100['Retain Accuracy'].idxmax()]\n",
    "\n",
    "    # Analyze cross-dataset results including ImageNet\n",
    "    cross_dataset = formatted_tables['cross_dataset']\n",
    "    dataset_summary = cross_dataset.groupby('Dataset').agg({\n",
    "        'Unlearned Class Accuracy': 'mean',\n",
    "        'Retained Class Accuracy': 'mean',\n",
    "        'Runtime (s)': 'mean',\n",
    "        'Post-processing Effectiveness': 'mean'\n",
    "    })\n",
    "\n",
    "    # Print analysis\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(f\"\\nCIFAR-10:\")\n",
    "    print(f\"Best forgetting: {best_forget_c10['Method']} ({best_forget_c10['Forget Accuracy']}%)\")\n",
    "    print(f\"Best retention: {best_retain_c10['Method']} ({best_retain_c10['Retain Accuracy']}%)\")\n",
    "\n",
    "    print(f\"\\nCIFAR-100:\")\n",
    "    print(f\"Best forgetting: {best_forget_c100['Method']} ({best_forget_c100['Class-wise Forget Rate']}%)\")\n",
    "    print(f\"Best retention: {best_retain_c100['Method']} ({best_retain_c100['Retain Accuracy']}%)\")\n",
    "\n",
    "    print(\"\\nCross-Dataset Performance Summary:\")\n",
    "    print(tabulate(dataset_summary.round(1), headers='keys', tablefmt='psql'))\n",
    "\n",
    "def load_dataset(dataset_name: str):\n",
    "    \"\"\"\n",
    "    Load and preprocess dataset based on name.\n",
    "    Supports: CIFAR-10, CIFAR-100, Fashion-MNIST, SVHN, and TinyImageNet\n",
    "   \n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset to load\n",
    "       \n",
    "    Returns:\n",
    "        tuple: ((x_train, y_train), (x_test, y_test)) or (None, None) if loading fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading {dataset_name} dataset...\")\n",
    "\n",
    "        if dataset_name == 'tiny_imagenet':\n",
    "            try:\n",
    "                root_dir = \"./tiny-imagenet-200\"\n",
    "                logger.info(\"Getting TinyImageNet datasets...\")\n",
    "               \n",
    "                # Get datasets using the TinyImageNetTF class\n",
    "                dataset = TinyImageNetTF(root_dir)\n",
    "                train_ds = dataset.get_dataset('train', batch_size=128, shuffle=True, augment=False)\n",
    "                val_ds = dataset.get_dataset('val', batch_size=128, shuffle=False, augment=False)\n",
    "               \n",
    "                logger.info(\"Converting TinyImageNet training data to numpy...\")\n",
    "                # Convert training data to numpy arrays\n",
    "                x_train_list = []\n",
    "                y_train_list = []\n",
    "                for images, labels in train_ds:\n",
    "                    x_train_list.append(images.numpy())\n",
    "                    y_train_list.append(labels.numpy())\n",
    "               \n",
    "                x_train = np.concatenate(x_train_list, axis=0)\n",
    "                y_train = np.concatenate(y_train_list, axis=0).reshape(-1, 1)\n",
    "               \n",
    "                logger.info(\"Converting TinyImageNet validation data to numpy...\")\n",
    "                # Convert validation data to numpy arrays\n",
    "                x_test_list = []\n",
    "                y_test_list = []\n",
    "                for images, labels in val_ds:\n",
    "                    x_test_list.append(images.numpy())\n",
    "                    y_test_list.append(labels.numpy())\n",
    "               \n",
    "                x_test = np.concatenate(x_test_list, axis=0)\n",
    "                y_test = np.concatenate(y_test_list, axis=0).reshape(-1, 1)\n",
    "               \n",
    "                logger.info(f\"TinyImageNet loaded: train shapes {x_train.shape}, {y_train.shape}\")\n",
    "                logger.info(f\"Number of classes: {len(np.unique(y_train))}\")\n",
    "               \n",
    "                return (x_train, y_train), (x_test, y_test)\n",
    "               \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading TinyImageNet: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                return None, None\n",
    "\n",
    "        elif dataset_name == 'cifar10':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "            logger.info(f\"CIFAR-10 loaded: train shapes {x_train.shape}, {y_train.shape}\")\n",
    "\n",
    "        elif dataset_name == 'cifar100':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "            logger.info(f\"CIFAR-100 loaded: train shapes {x_train.shape}, {y_train.shape}\")\n",
    "\n",
    "        elif dataset_name == 'fashion_mnist':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "            x_train = np.expand_dims(x_train, axis=-1)\n",
    "            x_test = np.expand_dims(x_test, axis=-1)\n",
    "            logger.info(f\"Fashion-MNIST loaded: train shapes {x_train.shape}, {y_train.shape}\")\n",
    "\n",
    "        elif dataset_name == 'svhn':\n",
    "            try:\n",
    "                train_ds = tfds.load('svhn_cropped', split='train', as_supervised=True)\n",
    "                test_ds = tfds.load('svhn_cropped', split='test', as_supervised=True)\n",
    "\n",
    "                # Convert training data\n",
    "                x_train_list = []\n",
    "                y_train_list = []\n",
    "                for image, label in train_ds:\n",
    "                    x_train_list.append(image.numpy())\n",
    "                    y_train_list.append(label.numpy())\n",
    "\n",
    "                # Convert test data\n",
    "                x_test_list = []\n",
    "                y_test_list = []\n",
    "                for image, label in test_ds:\n",
    "                    x_test_list.append(image.numpy())\n",
    "                    y_test_list.append(label.numpy())\n",
    "\n",
    "                x_train = np.array(x_train_list, dtype=np.float32)\n",
    "                y_train = np.array(y_train_list, dtype=np.int32).reshape(-1, 1)\n",
    "                x_test = np.array(x_test_list, dtype=np.float32)\n",
    "                y_test = np.array(y_test_list, dtype=np.int32).reshape(-1, 1)\n",
    "\n",
    "                logger.info(f\"SVHN loaded: train shapes {x_train.shape}, {y_train.shape}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load SVHN dataset: {str(e)}\")\n",
    "                return None, None\n",
    "\n",
    "        else:\n",
    "            logger.error(f\"Unknown dataset: {dataset_name}\")\n",
    "            return None, None\n",
    "\n",
    "        # Normalize pixel values if not TinyImageNet (already normalized)\n",
    "        if dataset_name != 'tiny_imagenet':\n",
    "            x_train = x_train.astype('float32') / 255.0\n",
    "            x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "        # Verify data integrity\n",
    "        assert x_train is not None and y_train is not None, \"Training data is None\"\n",
    "        assert x_test is not None and y_test is not None, \"Test data is None\"\n",
    "        assert len(x_train) == len(y_train), \"Training data and labels have different lengths\"\n",
    "        assert len(x_test) == len(y_test), \"Test data and labels have different lengths\"\n",
    "\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load dataset {dataset_name}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def create_data_generators(x_train, y_train, x_test, y_test, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create data generators with augmentation for training.\n",
    "    Ensures consistent class distribution between training and validation splits.\n",
    "   \n",
    "    Args:\n",
    "        x_train (np.ndarray): Training data\n",
    "        y_train (np.ndarray): Training labels\n",
    "        x_test (np.ndarray): Test data\n",
    "        y_test (np.ndarray): Test labels\n",
    "        batch_size (int): Batch size for the generators\n",
    "       \n",
    "    Returns:\n",
    "        tuple: (train_generator, validation_generator, test_generator) or (None, None, None) if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verify input data\n",
    "        if x_train is None or y_train is None or x_test is None or y_test is None:\n",
    "            raise ValueError(\"Input data cannot be None\")\n",
    "\n",
    "        # First, shuffle the training data to ensure random distribution of classes\n",
    "        indices = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        x_train = x_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        # Calculate validation split index (80-20 split)\n",
    "        validation_split = 0.2\n",
    "        split_idx = int(x_train.shape[0] * (1 - validation_split))\n",
    "\n",
    "        # Split the data manually to ensure class consistency\n",
    "        x_train_split = x_train[:split_idx]\n",
    "        y_train_split = y_train[:split_idx]\n",
    "        x_val_split = x_train[split_idx:]\n",
    "        y_val_split = y_train[split_idx:]\n",
    "\n",
    "        # Verify that all splits contain all classes\n",
    "        train_classes = np.unique(y_train_split)\n",
    "        val_classes = np.unique(y_val_split)\n",
    "        test_classes = np.unique(y_test)\n",
    "       \n",
    "        if not (np.all(np.isin(train_classes, val_classes)) and\n",
    "                np.all(np.isin(train_classes, test_classes))):\n",
    "            logger.warning(\"Class distribution mismatch detected between splits\")\n",
    "\n",
    "        # Create data generators with augmentation for training\n",
    "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        # Create generator for validation and test without augmentation\n",
    "        test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "        # Create generators with the manually split data\n",
    "        train_generator = train_datagen.flow(\n",
    "            x_train_split, y_train_split,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        validation_generator = test_datagen.flow(\n",
    "            x_val_split, y_val_split,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        test_generator = test_datagen.flow(\n",
    "            x_test, y_test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Log generator creation success\n",
    "        logger.info(f\"Created data generators successfully:\")\n",
    "        logger.info(f\"Training samples: {len(x_train_split)}\")\n",
    "        logger.info(f\"Validation samples: {len(x_val_split)}\")\n",
    "        logger.info(f\"Test samples: {len(x_test)}\")\n",
    "\n",
    "        return train_generator, validation_generator, test_generator\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create data generators: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def main():\n",
    "\n",
    "    try:\n",
    "        # Dataset configuration\n",
    "        datasets = ['cifar10', 'cifar100', 'fashion_mnist', 'svhn', 'tiny_imagenet']\n",
    "        forget_class = 0\n",
    "        results = []\n",
    "\n",
    "\n",
    "        # Enhanced training configuration with target metrics\n",
    "        base_config = {\n",
    "            'cifar10': {\n",
    "                'epochs': 15,\n",
    "                'batch_size': 64,\n",
    "                'initial_learning_rate': 0.002,\n",
    "                'model_type': 'simple',\n",
    "                'target_forget_acc': 0.99,\n",
    "                'target_retain_acc': 0.85,\n",
    "                'target_privacy': 0.90\n",
    "            },\n",
    "            'cifar100': {\n",
    "                'epochs': 20,\n",
    "                'batch_size': 128,\n",
    "                'initial_learning_rate': 0.001,\n",
    "                'model_type': 'resnet',\n",
    "                'target_forget_acc': 0.95,\n",
    "                'target_retain_acc': 0.80,\n",
    "                'target_privacy': 0.85\n",
    "            },\n",
    "            'fashion_mnist': {\n",
    "                'epochs': 12,\n",
    "                'batch_size': 64,\n",
    "                'initial_learning_rate': 0.0015,\n",
    "                'model_type': 'simple',\n",
    "                'target_forget_acc': 0.98,\n",
    "                'target_retain_acc': 0.88,\n",
    "                'target_privacy': 0.92\n",
    "            },\n",
    "            'svhn': {\n",
    "                'epochs': 15,\n",
    "                'batch_size': 128,\n",
    "                'initial_learning_rate': 0.0015,\n",
    "                'model_type': 'simple',\n",
    "                'target_forget_acc': 0.97,\n",
    "                'target_retain_acc': 0.86,\n",
    "                'target_privacy': 0.88\n",
    "            },\n",
    "            'tiny_imagenet': {\n",
    "                'epochs': 30,\n",
    "                'batch_size': 32,\n",
    "                'initial_learning_rate': 0.0001,\n",
    "                'model_type': 'resnet',\n",
    "                'target_forget_acc': 0.90,\n",
    "                'target_retain_acc': 0.75,\n",
    "                'target_privacy': 0.85\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        dataset_results = {}  # Store results by dataset\n",
    "\n",
    "        for dataset_name in datasets:\n",
    "            logger.info(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "\n",
    "            # Load and preprocess dataset\n",
    "            dataset = load_dataset(dataset_name)\n",
    "            if dataset is None:\n",
    "                logger.warning(f\"Skipping {dataset_name} due to loading failure\")\n",
    "                continue\n",
    "\n",
    "            (x_train, y_train), (x_test, y_test) = dataset\n",
    "            input_shape = x_train.shape[1:]\n",
    "            num_classes = len(np.unique(y_train))\n",
    "\n",
    "            # Create data generators with augmentation if needed\n",
    "            train_generator, validation_generator, test_generator = create_data_generators(\n",
    "                x_train, y_train, x_test, y_test, batch_size=base_config[dataset_name]['batch_size']\n",
    "            )\n",
    "\n",
    "            # Create and compile model\n",
    "            config = base_config[dataset_name]\n",
    "            model = create_model(\n",
    "                input_shape=input_shape,\n",
    "                num_classes=num_classes,\n",
    "                model_type=config['model_type']\n",
    "            )\n",
    "\n",
    "            # Enhanced callbacks with metric tracking\n",
    "            class MetricTracker(tf.keras.callbacks.Callback):\n",
    "                def on_epoch_end(self, epoch, logs={}):\n",
    "                    if logs.get('val_accuracy', 0) >= config['target_retain_acc']:\n",
    "                        logger.info(f\"Reached target retention accuracy at epoch {epoch}\")\n",
    "\n",
    "            callbacks = [\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=7,\n",
    "                    restore_best_weights=True,\n",
    "                    min_delta=0.001\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=3,\n",
    "                    min_lr=1e-6,\n",
    "                    verbose=1\n",
    "                ),\n",
    "                MetricTracker()\n",
    "            ]\n",
    "\n",
    "            # Train model\n",
    "            logger.info(f\"Starting training for {dataset_name}\")\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                validation_data=validation_generator,\n",
    "                epochs=config['epochs'],\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Prepare data for unlearning\n",
    "            forget_indices = (y_train == forget_class).reshape(-1)  # Reshape to 1D\n",
    "            forget_data = (x_train[forget_indices], y_train[forget_indices])\n",
    "            retain_data = (x_train[~forget_indices], y_train[~forget_indices])\n",
    "\n",
    "\n",
    "            # Initialize unlearning methods\n",
    "            unlearning_methods = ImprovedUnlearningMethods(model, dataset_name)\n",
    "\n",
    "            # Define methods to evaluate\n",
    "            methods = [\n",
    "                {\n",
    "                    'name': 'Gradient-based',\n",
    "                    'function': unlearning_methods.improved_gradient_unlearning,\n",
    "                    'args': (forget_data,),\n",
    "                    'expected_forget_acc': 0.95,\n",
    "                    'expected_retain_acc': 0.85\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Influence Functions',\n",
    "                    'function': unlearning_methods.improved_influence_functions,\n",
    "                    'args': (forget_data, retain_data),\n",
    "                    'expected_forget_acc': 0.97,\n",
    "                    'expected_retain_acc': 0.87\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Hessian-Guided',\n",
    "                    'function': unlearning_methods.improved_hessian_guided_unlearning,\n",
    "                    'args': (forget_data, retain_data),\n",
    "                    'expected_forget_acc': 0.99,\n",
    "                    'expected_retain_acc': 0.90\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Combined Method',\n",
    "                    'function': unlearning_methods.combined_unlearning,\n",
    "                    'args': (forget_data, retain_data),\n",
    "                    'expected_forget_acc': 0.99,\n",
    "                    'expected_retain_acc': 0.92\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            dataset_results[dataset_name] = []\n",
    "\n",
    "            # Apply and evaluate each method\n",
    "            for method in methods:\n",
    "                try:\n",
    "                    # Save initial state\n",
    "                    initial_weights = [w.numpy() for w in model.trainable_variables]\n",
    "\n",
    "                    # Apply method\n",
    "                    logger.info(f\"Applying {method['name']} to {dataset_name}\")\n",
    "                    start_time = time.time()\n",
    "                    method_time = method['function'](*method['args'])\n",
    "\n",
    "                    # Evaluate results\n",
    "                    method_results = evaluate_unlearning(model, x_test, y_test, forget_class)\n",
    "                    method_results['method'] = method['name']\n",
    "                    method_results['time'] = method_time\n",
    "                    method_results['dataset'] = dataset_name\n",
    "\n",
    "                    # Add performance validation\n",
    "                    method_results['meets_targets'] = (\n",
    "                        method_results['forget_acc'] >= method['expected_forget_acc'] and\n",
    "                        method_results['retain_acc'] >= method['expected_retain_acc']\n",
    "                    )\n",
    "\n",
    "                    results.append(method_results)\n",
    "                    dataset_results[dataset_name].append(method_results)\n",
    "\n",
    "                    logger.info(f\"Completed {method['name']} for {dataset_name}\")\n",
    "                    if not method_results['meets_targets']:\n",
    "                        logger.warning(f\"{method['name']} did not meet expected performance targets\")\n",
    "\n",
    "                    # Restore model for next method\n",
    "                    for var, weights in zip(model.trainable_variables, initial_weights):\n",
    "                        var.assign(weights)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error applying {method['name']} to {dataset_name}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "            # Apply post-processing methods\n",
    "            post_processing_methods = [\n",
    "                {\n",
    "                    'name': 'Post Unlearning Masking',\n",
    "                    'function': unlearning_methods.improved_post_unlearning_masking,\n",
    "                    'args': tuple()\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Post Unlearning Inpainting',\n",
    "                    'function': unlearning_methods.improved_post_unlearning_inpainting,\n",
    "                    'args': tuple()\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            for method in post_processing_methods:\n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    method_time = method['function'](*method['args'])\n",
    "\n",
    "                    method_results = evaluate_unlearning(model, x_test, y_test, forget_class)\n",
    "                    method_results['method'] = method['name']\n",
    "                    method_results['time'] = method_time\n",
    "                    method_results['dataset'] = dataset_name\n",
    "\n",
    "                    results.append(method_results)\n",
    "                    dataset_results[dataset_name].append(method_results)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error applying {method['name']} to {dataset_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            # Cleanup\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "        # Process and display results\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Generate and save detailed tables\n",
    "        print(\"\\nDetailed Results Tables:\")\n",
    "        print_formatted_tables(results_df)\n",
    "        save_tables_to_file(results_df, 'unlearning_detailed_results.txt')\n",
    "\n",
    "        # Save raw results\n",
    "        results_df.to_csv('unlearning_raw_results.csv', index=False)\n",
    "\n",
    "        # Analyze results\n",
    "        print(\"\\nResults Analysis:\")\n",
    "        analyze_results(results_df)\n",
    "\n",
    "        logger.info(\"Results processing completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
